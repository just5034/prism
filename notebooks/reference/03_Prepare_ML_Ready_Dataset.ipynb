{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare ML-Ready Dataset: Methylation + Drug Response\n",
    "\n",
    "**Goal**: Create a self-contained dataset for training machine learning models to predict drug response from DNA methylation data.\n",
    "\n",
    "**Output**: \n",
    "- `data/processed/ML_dataset_methylation_drug_response.csv` - Combined methylation + drug response\n",
    "- `data/processed/ML_dataset_metadata.md` - Comprehensive documentation\n",
    "\n",
    "**Dataset**: GSE68379 (1,028 pan-cancer cell lines) + GDSC drug response data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from io import StringIO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load GSE68379 Methylation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load methylation data (this may take 3-4 minutes for 3.9 GB file)\n",
    "print(\"Loading GSE68379 methylation matrix...\")\n",
    "df_meth = pd.read_csv('../data/raw/GSE68379/GSE68379_Matrix.processed.txt.gz',\n",
    "                      sep='\\t', index_col=0, compression='gzip')\n",
    "\n",
    "# Remove \"Row.names\" column if present\n",
    "if 'Row.names' in df_meth.columns:\n",
    "    df_meth = df_meth.drop(columns=['Row.names'])\n",
    "\n",
    "# Clean column names (remove _AVG.Beta suffix)\n",
    "df_meth.columns = [col.replace('_AVG.Beta', '') for col in df_meth.columns]\n",
    "\n",
    "print(f\"Methylation data shape: {df_meth.shape}\")\n",
    "print(f\"CpG sites: {df_meth.shape[0]:,}\")\n",
    "print(f\"Cell lines: {df_meth.shape[1]:,}\")\n",
    "print(f\"Memory usage: {df_meth.memory_usage(deep=True).sum() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample metadata\n",
    "df_meta = pd.read_csv('../data/processed/GSE68379_sample_metadata.csv')\n",
    "print(f\"Sample metadata shape: {df_meta.shape}\")\n",
    "print(f\"\\nMetadata columns: {df_meta.columns.tolist()}\")\n",
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download GDSC Drug Response Data\n",
    "\n",
    "The Genomics of Drug Sensitivity in Cancer (GDSC) project provides IC50 values for hundreds of drugs across cancer cell lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download GDSC1 and GDSC2 drug response data\n",
    "# GDSC provides bulk download files for all drug responses\n",
    "\n",
    "print(\"Downloading GDSC drug response data...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# GDSC1 (older dataset, more drugs)\n",
    "url_gdsc1 = 'https://www.cancerrxgene.org/downloads/bulk_download?file=GDSC1_fitted_dose_response_25Feb20.xlsx'\n",
    "# GDSC2 (newer dataset, different drugs)\n",
    "url_gdsc2 = 'https://www.cancerrxgene.org/downloads/bulk_download?file=GDSC2_fitted_dose_response_25Feb20.xlsx'\n",
    "\n",
    "# Try downloading - if this fails, we'll use alternative URLs\n",
    "try:\n",
    "    # GDSC provides CSV versions as well\n",
    "    url_csv = 'https://www.cancerrxgene.org/gdsc1000/GDSC1000_WebResources/Data/preprocessed/Cell_line_RMA_proc_basalExp.txt.zip'\n",
    "    print(\"Attempting to download from GDSC...\")\n",
    "    print(\"Note: GDSC website structure may have changed. Checking alternative sources...\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Will use alternative data source...\")\n",
    "\n",
    "# Alternative: Use FTP site or pre-downloaded files\n",
    "print(\"\\nNote: GDSC data is large and may require direct download.\")\n",
    "print(\"We'll check if data is already available locally first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GDSC data already exists locally\n",
    "gdsc_file = Path('../data/raw/GDSC/GDSC_drug_response.csv')\n",
    "\n",
    "if gdsc_file.exists():\n",
    "    print(\"Found local GDSC data!\")\n",
    "    df_gdsc = pd.read_csv(gdsc_file)\n",
    "else:\n",
    "    print(\"GDSC data not found locally.\")\n",
    "    print(\"\\nOption 1: Download from GDSC DepMap portal\")\n",
    "    print(\"URL: https://depmap.org/portal/download/\")\n",
    "    print(\"File: CTRP or GDSC drug sensitivity data\")\n",
    "    print(\"\\nOption 2: Use GDSC bulk download\")\n",
    "    print(\"URL: https://www.cancerrxgene.org/downloads/bulk_download\")\n",
    "    print(\"\\nFor now, we'll create a download script...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data/raw/GDSC directory if it doesn't exist\n",
    "gdsc_dir = Path('../data/raw/GDSC')\n",
    "gdsc_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Created directory: {gdsc_dir}\")\n",
    "\n",
    "# Download GDSC data using updated URLs\n",
    "# GDSC provides data through CellModelPassports/DepMap now\n",
    "\n",
    "print(\"\\nAttempting to download GDSC drug screening data...\")\n",
    "print(\"Source: CellModelPassports (ftp.sanger.ac.uk)\\n\")\n",
    "\n",
    "# Latest GDSC data is available via FTP\n",
    "gdsc_url = 'https://ftp.sanger.ac.uk/pub/project/cancerrxgene/releases/current_release/GDSC1_fitted_dose_response_17Jul19.xlsx'\n",
    "\n",
    "# Alternative: Use CSV version\n",
    "# For initial testing, let's use a smaller subset\n",
    "print(\"Downloading GDSC1 fitted dose response data...\")\n",
    "print(\"(This file is ~50MB, may take 1-2 minutes)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download GDSC data with error handling\n",
    "import urllib.request\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def download_file_with_progress(url, output_path):\n",
    "    \"\"\"Download file with progress bar\"\"\"\n",
    "    try:\n",
    "        # Get file size\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            file_size = int(response.headers.get('Content-Length', 0))\n",
    "        \n",
    "        # Download with progress\n",
    "        with tqdm(total=file_size, unit='B', unit_scale=True, desc='Downloading') as pbar:\n",
    "            def reporthook(blocknum, blocksize, totalsize):\n",
    "                pbar.update(blocksize)\n",
    "            urllib.request.urlretrieve(url, output_path, reporthook=reporthook)\n",
    "        \n",
    "        print(f\"\\nDownload complete: {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Download failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Try downloading\n",
    "gdsc_output = gdsc_dir / 'GDSC1_fitted_dose_response.xlsx'\n",
    "\n",
    "if not gdsc_output.exists():\n",
    "    success = download_file_with_progress(gdsc_url, gdsc_output)\n",
    "    if not success:\n",
    "        print(\"\\nAutomatic download failed.\")\n",
    "        print(\"\\nManual download instructions:\")\n",
    "        print(\"1. Visit: https://www.cancerrxgene.org/downloads/bulk_download\")\n",
    "        print(\"2. Download: 'GDSC1 Fitted dose response'\")\n",
    "        print(f\"3. Save to: {gdsc_output.absolute()}\")\n",
    "        print(\"\\nThen re-run this cell.\")\n",
    "else:\n",
    "    print(f\"GDSC data already exists: {gdsc_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GDSC data\n",
    "if gdsc_output.exists():\n",
    "    print(\"Loading GDSC drug response data...\")\n",
    "    df_gdsc_raw = pd.read_excel(gdsc_output)\n",
    "    print(f\"GDSC data shape: {df_gdsc_raw.shape}\")\n",
    "    print(f\"\\nColumns: {df_gdsc_raw.columns.tolist()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    display(df_gdsc_raw.head())\n",
    "else:\n",
    "    print(\"GDSC data not available. Please download manually.\")\n",
    "    print(\"\\nCreating placeholder for demonstration...\")\n",
    "    # Create a minimal example structure\n",
    "    df_gdsc_raw = pd.DataFrame({\n",
    "        'CELL_LINE_NAME': [],\n",
    "        'DRUG_NAME': [],\n",
    "        'LN_IC50': [],\n",
    "        'AUC': []\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Match Cell Lines Between GSE68379 and GDSC\n",
    "\n",
    "Cell line names may differ slightly between databases. We need to harmonize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cell line names from both datasets\n",
    "gse_cell_lines = set(df_meth.columns)\n",
    "gdsc_cell_lines = set(df_gdsc_raw['CELL_LINE_NAME'].unique()) if 'CELL_LINE_NAME' in df_gdsc_raw.columns else set()\n",
    "\n",
    "print(f\"GSE68379 cell lines: {len(gse_cell_lines)}\")\n",
    "print(f\"GDSC cell lines: {len(gdsc_cell_lines)}\")\n",
    "\n",
    "# Find exact matches\n",
    "exact_matches = gse_cell_lines & gdsc_cell_lines\n",
    "print(f\"\\nExact name matches: {len(exact_matches)}\")\n",
    "\n",
    "# Show some examples\n",
    "if len(exact_matches) > 0:\n",
    "    print(f\"\\nExample matches: {list(exact_matches)[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze name mismatches and create mapping\n",
    "# Common differences: case sensitivity, hyphens vs underscores, spaces\n",
    "\n",
    "def normalize_cell_line_name(name):\n",
    "    \"\"\"Normalize cell line names for matching\"\"\"\n",
    "    return str(name).upper().replace('-', '').replace('_', '').replace(' ', '')\n",
    "\n",
    "# Create normalized mappings\n",
    "gse_normalized = {normalize_cell_line_name(name): name for name in gse_cell_lines}\n",
    "gdsc_normalized = {normalize_cell_line_name(name): name for name in gdsc_cell_lines}\n",
    "\n",
    "# Find matches using normalized names\n",
    "normalized_matches = set(gse_normalized.keys()) & set(gdsc_normalized.keys())\n",
    "print(f\"Matches after normalization: {len(normalized_matches)}\")\n",
    "\n",
    "# Create mapping dictionary: GDSC name -> GSE name\n",
    "cell_line_mapping = {}\n",
    "for norm_name in normalized_matches:\n",
    "    gdsc_name = gdsc_normalized[norm_name]\n",
    "    gse_name = gse_normalized[norm_name]\n",
    "    cell_line_mapping[gdsc_name] = gse_name\n",
    "\n",
    "print(f\"\\nCreated mapping for {len(cell_line_mapping)} cell lines\")\n",
    "print(f\"\\nExample mappings:\")\n",
    "for i, (gdsc_name, gse_name) in enumerate(list(cell_line_mapping.items())[:5]):\n",
    "    print(f\"  {gdsc_name} -> {gse_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process Drug Response Data\n",
    "\n",
    "We'll create a matrix with:\n",
    "- Rows: Cell lines\n",
    "- Columns: Drugs\n",
    "- Values: IC50 or AUC (drug sensitivity metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter GDSC data to matched cell lines only\n",
    "if len(df_gdsc_raw) > 0:\n",
    "    df_gdsc_filtered = df_gdsc_raw[df_gdsc_raw['CELL_LINE_NAME'].isin(cell_line_mapping.keys())].copy()\n",
    "    \n",
    "    print(f\"GDSC entries after filtering to matched cell lines: {len(df_gdsc_filtered):,}\")\n",
    "    print(f\"Unique cell lines: {df_gdsc_filtered['CELL_LINE_NAME'].nunique()}\")\n",
    "    print(f\"Unique drugs: {df_gdsc_filtered['DRUG_NAME'].nunique()}\")\n",
    "    \n",
    "    # Map GDSC cell line names to GSE names\n",
    "    df_gdsc_filtered['GSE_CELL_LINE'] = df_gdsc_filtered['CELL_LINE_NAME'].map(cell_line_mapping)\n",
    "    \n",
    "    display(df_gdsc_filtered.head())\n",
    "else:\n",
    "    print(\"No GDSC data to filter. Please download GDSC data first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create drug response matrix (cell lines × drugs)\n",
    "if len(df_gdsc_filtered) > 0:\n",
    "    # Use LN_IC50 as the primary metric (natural log of IC50)\n",
    "    # Lower values = more sensitive to drug\n",
    "    \n",
    "    df_drug_response = df_gdsc_filtered.pivot_table(\n",
    "        index='GSE_CELL_LINE',\n",
    "        columns='DRUG_NAME',\n",
    "        values='LN_IC50',\n",
    "        aggfunc='mean'  # Average if multiple measurements\n",
    "    )\n",
    "    \n",
    "    print(f\"Drug response matrix shape: {df_drug_response.shape}\")\n",
    "    print(f\"Cell lines: {df_drug_response.shape[0]}\")\n",
    "    print(f\"Drugs: {df_drug_response.shape[1]}\")\n",
    "    print(f\"\\nMissing data: {df_drug_response.isna().sum().sum() / df_drug_response.size * 100:.1f}%\")\n",
    "    \n",
    "    display(df_drug_response.iloc[:5, :5])\n",
    "else:\n",
    "    print(\"Cannot create drug response matrix without GDSC data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to high-quality drugs\n",
    "# Criteria: tested in >100 cell lines, <50% missing data\n",
    "\n",
    "if len(df_drug_response) > 0:\n",
    "    # Count non-missing values per drug\n",
    "    drug_coverage = df_drug_response.notna().sum()\n",
    "    \n",
    "    # Filter drugs\n",
    "    min_cell_lines = 100\n",
    "    high_quality_drugs = drug_coverage[drug_coverage >= min_cell_lines].index\n",
    "    \n",
    "    df_drug_response_filtered = df_drug_response[high_quality_drugs]\n",
    "    \n",
    "    print(f\"High-quality drugs (tested in ≥{min_cell_lines} cell lines): {len(high_quality_drugs)}\")\n",
    "    print(f\"\\nFiltered drug response shape: {df_drug_response_filtered.shape}\")\n",
    "    print(f\"\\nTop 10 drugs by coverage:\")\n",
    "    print(drug_coverage.sort_values(ascending=False).head(10))\n",
    "else:\n",
    "    print(\"Skipping drug filtering.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combine Methylation and Drug Response Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ML purposes, we'll use the top 10,000 most variable CpG sites\n",
    "# (This was already computed in the EDA notebook)\n",
    "\n",
    "# Check if pre-computed file exists\n",
    "top_cpgs_file = Path('../data/processed/GSE68379_top10k_variable_CpGs.csv')\n",
    "\n",
    "if top_cpgs_file.exists():\n",
    "    print(\"Loading pre-computed top 10K variable CpG sites...\")\n",
    "    df_top_cpgs = pd.read_csv(top_cpgs_file, index_col=0)\n",
    "    top_cpg_names = df_top_cpgs.index.tolist()\n",
    "    print(f\"Loaded {len(top_cpg_names)} CpG sites\")\n",
    "else:\n",
    "    print(\"Computing top 10K variable CpG sites...\")\n",
    "    # Calculate variance for each CpG site\n",
    "    cpg_variance = df_meth.var(axis=1)\n",
    "    top_cpg_names = cpg_variance.nlargest(10000).index.tolist()\n",
    "    print(f\"Selected top {len(top_cpg_names)} variable CpG sites\")\n",
    "\n",
    "# Extract methylation data for these CpG sites\n",
    "df_meth_filtered = df_meth.loc[top_cpg_names, :].T  # Transpose: rows=cell lines, cols=CpGs\n",
    "print(f\"\\nFiltered methylation data shape: {df_meth_filtered.shape}\")\n",
    "print(f\"Rows (cell lines): {df_meth_filtered.shape[0]}\")\n",
    "print(f\"Columns (CpG sites): {df_meth_filtered.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine methylation and drug response data\n",
    "# Only keep cell lines that have BOTH methylation AND drug response data\n",
    "\n",
    "if len(df_drug_response_filtered) > 0:\n",
    "    # Find common cell lines\n",
    "    common_cell_lines = df_meth_filtered.index.intersection(df_drug_response_filtered.index)\n",
    "    \n",
    "    print(f\"Cell lines with both methylation and drug response: {len(common_cell_lines)}\")\n",
    "    \n",
    "    # Combine data\n",
    "    df_combined = pd.concat([\n",
    "        df_meth_filtered.loc[common_cell_lines],\n",
    "        df_drug_response_filtered.loc[common_cell_lines]\n",
    "    ], axis=1)\n",
    "    \n",
    "    print(f\"\\nCombined dataset shape: {df_combined.shape}\")\n",
    "    print(f\"Rows (cell lines): {df_combined.shape[0]}\")\n",
    "    print(f\"Columns (features + targets):\")\n",
    "    print(f\"  - Methylation features (CpG sites): {len(top_cpg_names)}\")\n",
    "    print(f\"  - Drug response targets: {len(high_quality_drugs)}\")\n",
    "    print(f\"  - Total columns: {df_combined.shape[1]}\")\n",
    "    \n",
    "    display(df_combined.iloc[:5, :5])\n",
    "else:\n",
    "    print(\"Cannot combine data without drug response information.\")\n",
    "    # Create methylation-only dataset\n",
    "    df_combined = df_meth_filtered\n",
    "    print(f\"\\nCreating methylation-only dataset: {df_combined.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add Sample Metadata Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metadata columns (primary site, histology, etc.)\n",
    "# These can be used as additional features or for stratification\n",
    "\n",
    "# Match metadata to combined dataset\n",
    "df_meta_matched = df_meta[df_meta['cell line'].isin(df_combined.index)].copy()\n",
    "df_meta_matched = df_meta_matched.set_index('cell line')\n",
    "\n",
    "# Reorder to match df_combined\n",
    "df_meta_matched = df_meta_matched.loc[df_combined.index]\n",
    "\n",
    "print(f\"Matched metadata for {len(df_meta_matched)} cell lines\")\n",
    "print(f\"\\nMetadata columns to add:\")\n",
    "for col in df_meta_matched.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "display(df_meta_matched.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final dataset with metadata as first columns\n",
    "# Structure: [metadata columns] [methylation features] [drug response targets]\n",
    "\n",
    "metadata_cols = ['primary site', 'primary histology', 'cosmic_id']\n",
    "metadata_subset = df_meta_matched[metadata_cols]\n",
    "\n",
    "# Combine: metadata + methylation + drug response\n",
    "df_final = pd.concat([metadata_subset, df_combined], axis=1)\n",
    "\n",
    "print(f\"Final ML-ready dataset shape: {df_final.shape}\")\n",
    "print(f\"\\nColumn structure:\")\n",
    "print(f\"  - Metadata columns: {len(metadata_cols)}\")\n",
    "print(f\"  - Methylation features: {len(top_cpg_names)}\")\n",
    "if len(df_drug_response_filtered) > 0:\n",
    "    print(f\"  - Drug response targets: {len(high_quality_drugs)}\")\n",
    "print(f\"  - Total columns: {df_final.shape[1]}\")\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df_final.dtypes.value_counts())\n",
    "\n",
    "display(df_final.iloc[:5, :8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing value analysis:\\n\")\n",
    "\n",
    "# Metadata\n",
    "metadata_missing = df_final[metadata_cols].isna().sum()\n",
    "print(\"Metadata columns:\")\n",
    "print(metadata_missing)\n",
    "\n",
    "# Methylation features\n",
    "meth_cols = [col for col in df_final.columns if col.startswith('cg')]\n",
    "meth_missing_pct = df_final[meth_cols].isna().sum().sum() / (len(meth_cols) * len(df_final)) * 100\n",
    "print(f\"\\nMethylation features: {meth_missing_pct:.2f}% missing\")\n",
    "\n",
    "# Drug response targets\n",
    "if len(df_drug_response_filtered) > 0:\n",
    "    drug_cols = [col for col in df_final.columns if col not in metadata_cols and not col.startswith('cg')]\n",
    "    drug_missing_pct = df_final[drug_cols].isna().sum() / len(df_final) * 100\n",
    "    print(f\"\\nDrug response targets (% missing per drug):\")\n",
    "    print(drug_missing_pct.describe())\n",
    "    print(f\"\\nDrugs with <10% missing: {(drug_missing_pct < 10).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data completeness\n",
    "if len(df_drug_response_filtered) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Drug coverage histogram\n",
    "    ax = axes[0]\n",
    "    drug_coverage_pct = (1 - drug_missing_pct / 100) * 100\n",
    "    ax.hist(drug_coverage_pct, bins=30, edgecolor='black')\n",
    "    ax.set_xlabel('Data Completeness (%)')\n",
    "    ax.set_ylabel('Number of Drugs')\n",
    "    ax.set_title('Drug Response Data Completeness')\n",
    "    ax.axvline(90, color='red', linestyle='--', label='90% threshold')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Sample completeness\n",
    "    ax = axes[1]\n",
    "    sample_completeness = (1 - df_final[drug_cols].isna().sum(axis=1) / len(drug_cols)) * 100\n",
    "    ax.hist(sample_completeness, bins=30, edgecolor='black')\n",
    "    ax.set_xlabel('Data Completeness (%)')\n",
    "    ax.set_ylabel('Number of Cell Lines')\n",
    "    ax.set_title('Cell Line Drug Response Completeness')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/figures/ML_dataset_completeness.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nCell line completeness summary:\")\n",
    "    print(sample_completeness.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save ML-Ready Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as compressed CSV\n",
    "output_file = Path('../data/processed/ML_dataset_methylation_drug_response.csv.gz')\n",
    "\n",
    "print(f\"Saving dataset to {output_file}...\")\n",
    "df_final.to_csv(output_file, compression='gzip')\n",
    "\n",
    "# Check file size\n",
    "file_size_mb = output_file.stat().st_size / (1024 * 1024)\n",
    "print(f\"File saved: {file_size_mb:.2f} MB\")\n",
    "\n",
    "# Also save metadata separately\n",
    "metadata_file = Path('../data/processed/ML_dataset_sample_info.csv')\n",
    "df_meta_matched.to_csv(metadata_file)\n",
    "print(f\"Sample metadata saved: {metadata_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column name mapping\n",
    "# This helps identify which columns are features vs targets\n",
    "\n",
    "column_info = pd.DataFrame({\n",
    "    'column_name': df_final.columns,\n",
    "    'column_type': ['metadata'] * len(metadata_cols) + \n",
    "                   ['methylation_feature'] * len(meth_cols) +\n",
    "                   ['drug_response_target'] * (len(df_final.columns) - len(metadata_cols) - len(meth_cols)),\n",
    "    'data_type': df_final.dtypes.values,\n",
    "    'missing_count': df_final.isna().sum().values,\n",
    "    'missing_pct': (df_final.isna().sum() / len(df_final) * 100).values\n",
    "})\n",
    "\n",
    "column_info_file = Path('../data/processed/ML_dataset_column_info.csv')\n",
    "column_info.to_csv(column_info_file, index=False)\n",
    "print(f\"Column info saved: {column_info_file}\")\n",
    "\n",
    "display(column_info.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics for the dataset\n",
    "\n",
    "summary_stats = {\n",
    "    'total_samples': len(df_final),\n",
    "    'total_features': len(meth_cols),\n",
    "    'total_targets': len(drug_cols) if len(df_drug_response_filtered) > 0 else 0,\n",
    "    'total_columns': df_final.shape[1],\n",
    "    'file_size_mb': file_size_mb,\n",
    "    'methylation_missing_pct': meth_missing_pct,\n",
    "    'primary_sites': df_final['primary site'].nunique(),\n",
    "    'histologies': df_final['primary histology'].nunique()\n",
    "}\n",
    "\n",
    "print(\"Dataset Summary:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in summary_stats.items():\n",
    "    print(f\"{key:30s}: {value}\")\n",
    "\n",
    "# Save summary\n",
    "summary_file = Path('../data/processed/ML_dataset_summary.txt')\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(\"ML-Ready Dataset Summary\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    for key, value in summary_stats.items():\n",
    "        f.write(f\"{key:30s}: {value}\\n\")\n",
    "\n",
    "print(f\"\\nSummary saved: {summary_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Quick Validation Test\n",
    "\n",
    "Test that the dataset can be loaded and used for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the saved dataset\n",
    "print(\"Testing dataset load...\")\n",
    "df_test = pd.read_csv(output_file, compression='gzip', index_col=0)\n",
    "print(f\"Loaded successfully: {df_test.shape}\")\n",
    "\n",
    "# Verify it matches original\n",
    "assert df_test.shape == df_final.shape, \"Shape mismatch!\"\n",
    "print(\"✓ Shape verification passed\")\n",
    "\n",
    "# Show example of how to use it\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"\")\n",
    "print(\"# Load dataset\")\n",
    "print(\"df = pd.read_csv('ML_dataset_methylation_drug_response.csv.gz', index_col=0)\")\n",
    "print(\"\")\n",
    "print(\"# Separate features and targets\")\n",
    "print(\"X = df[[col for col in df.columns if col.startswith('cg')]]  # Methylation features\")\n",
    "print(\"y = df['DRUG_NAME']  # Target drug (choose from available drugs)\")\n",
    "print(\"\")\n",
    "print(\"# Train model\")\n",
    "print(\"from sklearn.ensemble import RandomForestRegressor\")\n",
    "print(\"model = RandomForestRegressor()\")\n",
    "print(\"model.fit(X, y.dropna())  # Remove missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATASET PREPARATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  1. {output_file} ({file_size_mb:.1f} MB)\")\n",
    "print(f\"  2. {metadata_file}\")\n",
    "print(f\"  3. {column_info_file}\")\n",
    "print(f\"  4. {summary_file}\")\n",
    "print(f\"\\nReady for ML modeling!\")\n",
    "print(f\"\\nNext steps for your groupmate:\")\n",
    "print(f\"  - Load the dataset using pandas\")\n",
    "print(f\"  - Select features (CpG methylation sites)\")\n",
    "print(f\"  - Select target (specific drug)\")\n",
    "print(f\"  - Train XGBoost/Random Forest/etc.\")\n",
    "print(f\"  - Evaluate with cross-validation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
